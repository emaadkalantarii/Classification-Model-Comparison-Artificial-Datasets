# Supervised Learning - Classification Models Comparison

## Project Overview

This project is a part of the Knowledge Discovery and Data Mining course. It focuses on comparing various supervised learning classification models using scikit-learn. The primary goal is to create two artificially generated datasets, train different classifiers on them, evaluate their performance, and visualize their decision boundaries.

## Project Objectives

* To create two distinct 2D binary classification datasets:
    * Dataset 1: A linearly separable dataset.
    * Dataset 2: Dataset 1 with added outliers to test model robustness.
* To split these datasets into training and testing sets.
* To train and evaluate the following classification models on both datasets:
    * k-Nearest Neighbors (k-NN)
    * Naive Bayes (GaussianNB)
    * Decision Trees
    * Random Forests
    * Support Vector Machine (SVC)
    * Artificial Neural Network (MLPClassifier)
* To report and discuss the classification accuracy and confusion matrices for each model on both training and testing data.
* To visualize the decision boundaries of the trained classifiers for both datasets.

## Datasets

Two artificially generated datasets are used in this project, each with two continuous real number attributes for a binary classification problem.

### Dataset 1
* **Creation:** Generated using `sklearn.datasets.make_classification`.
* **Characteristics:**
    * 80 data points in total.
    * Two classes (0 and 1), with 40 data points belonging to each class.
    * Two features (Attribute\_1, Attribute\_2).
    * Classes are well-separated (`class_sep=2.0`).
* The notebook includes a scatter plot visualization of this dataset.

### Dataset 2
* **Creation:** Derived from Dataset 1 by adding outliers.
* **Characteristics:**
    * Dataset 1 + 8 additional data points (4 outliers for each class).
    * Outliers are generated by taking the class mean and shifting it by 3 times the standard deviation for each feature, then adding some random noise.
    * Total of 88 data points.
* The notebook includes a scatter plot visualization of this dataset with the added outliers.

## Methodology

1.  **Dataset Generation:**
    * Dataset 1 is created using `make_classification` with specified parameters for samples, features, classes, and class separation.
    * Dataset 2 is created by defining a function `add_outliers` which introduces 4 outliers for each class to Dataset 1. These outliers are positioned further from the class means.

2.  **Data Splitting:**
    * Both Dataset 1 and Dataset 2 are split into training and testing sets using `train_test_split` from `sklearn.model_selection`.
    * A test size of 30% (test\_size=0.3) is used.
    * `random_state=42` is set for reproducibility.
    * The notebook provides descriptive statistics and value counts for the labels in the resulting training and testing sets for both datasets.

3.  **Model Training and Evaluation:**
    * A dictionary of classifiers is defined, including k-NN, Naive Bayes, Decision Tree, Random Forest, SVC, and MLPClassifier.
    * A function `train_eval_classifiers` is created to:
        * Fit each classifier on the training data.
        * Make predictions on both training and testing data.
        * Calculate and print training accuracy and testing accuracy using `accuracy_score`.
        * Calculate and print the confusion matrix for the test data using `confusion_matrix`.
    * This function is called for both Dataset 1 and Dataset 2 training/testing splits.

4.  **Decision Boundary Visualization:**
    * A function `plot_decision_boundary` is defined to visualize the decision boundaries for each classifier.
    * This function:
        * Fits the classifier on the provided data (X, y).
        * Creates a mesh grid of points to cover the feature space.
        * Predicts the class for each point in the mesh grid.
        * Uses `plt.contourf` to plot the decision regions.
        * Scatters the original data points on top of the decision regions.
    * The decision boundaries are plotted for each classifier on both Dataset 1 (using `x_1_train`) and Dataset 2 (using `x_2_train`). *(Note: The notebook code for plotting decision boundaries for Dataset 2 seems to be missing, but the function is defined and used for Dataset 1. It's implied that a similar process would be followed for Dataset 2).*

## Classification Models Used

The following classifiers from `scikit-learn` are compared:
* `KNeighborsClassifier`
* `GaussianNB`
* `DecisionTreeClassifier`
* `RandomForestClassifier`
* `SVC` (Support Vector Machine)
* `MLPClassifier` (Artificial Neural Network)

## Results

The notebook outputs the following for each classifier on both Dataset 1 and Dataset 2:
* **Training Accuracy:** The accuracy of the model on the data it was trained on.
* **Test Accuracy:** The accuracy of the model on unseen test data.
* **Confusion Matrix:** A matrix showing the true positives, true negatives, false positives, and false negatives on the test data.

The notebook also includes visualizations of the decision boundaries for each model on Dataset 1. These plots help in understanding how each model separates the classes in the feature space.

*(A detailed discussion of the results, comparing model performance and the impact of outliers, would typically be included in the project report based on the outputted accuracies and confusion matrices.)*

## Requirements / Dependencies

To run this notebook, you will need Python 3 and the following libraries:
* `numpy`
* `pandas`
* `matplotlib`
* `scikit-learn` (sklearn)

You can install these libraries using pip:
```bash
pip install numpy pandas matplotlib scikit-learn
